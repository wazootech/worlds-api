---
title: "Local Setup"
description: "How to run the Worlds Platform™ ecosystem locally."
---

The Worlds Platform™ is designed with a **local-first** philosophy. You can boot the entire ecosystem—including the Management Console and any number of World API instances—using only your local filesystem and Deno runtime.

## Prerequisites

To develop on the Worlds Platform™, you'll need the following tools:

- **Deno** (latest) for the Server, SDK, and CLI.
- **Node.js** (v20+) for the Console and Documentation.
- **Git** for version control.

## Setup the console

The Console orchestrates all other resources. In local mode, it uses `data/workos.json` as a mock identity provider.

<Steps>
<Step title="Clone & Install">

```bash
git clone https://github.com/wazootech/worlds.git
cd worlds/packages/console
npm install
```

</Step>
<Step title="Environment Configuration">

Copy the example environment file. **Skip the WorkOS variables**, to trigger Local Dev Mode.

```bash
cp .env.example .env
```

</Step>
<Step title="Run the Console">

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

</Step>
</Steps>

## Booting world instances

Once the Console is running, it will automatically manage local World API processes.

- **Automatic Boot**: On startup, the Console checks `data/workos.json` and spawns a `deno serve` process for every local organization found.
- **Dynamic Provisioning**: When you create a new Organization in the Console UI, it will:
  1. Generate a local API Key.
  2. Create a local SQLite database in `data/{org_id}/worlds.db`.
  3. Spawn a new World API server on an available local port.

## Customizing the local user

In Local Dev Mode, you can customize the identity of the mock user session by setting environment variables in `packages/console/.env`:

```dotenv
LOCAL_USER_ID="admin"
LOCAL_USER_EMAIL="admin@wazoo.dev"
LOCAL_USER_FIRST_NAME="System"
LOCAL_USER_LAST_NAME="Admin"
```

These values are used to initialize the `data/workos.json` file if it doesn't already exist.

## Configuration Reference

Here's a list of environment variables you can set for local development:

| Variable                  | Description                                                       |
| :------------------------ | :---------------------------------------------------------------- |
| `LOCAL_USER_ID`           | (Optional) User ID for the mock local user.                       |
| `LOCAL_USER_EMAIL`        | (Optional) Email for the mock local user.                         |
| `LOCAL_USER_FIRST_NAME`   | (Optional) First name for the mock local user.                    |
| `LOCAL_USER_LAST_NAME`    | (Optional) Last name for the mock local user.                     |
| `GOOGLE_API_KEY`          | (Optional) For high-quality Gemini embeddings.                    |
| `OLLAMA_BASE_URL`         | (Optional) Ollama API URL (defaults to `http://127.0.0.1:11434`). |
| `OLLAMA_EMBEDDINGS_MODEL` | (Optional) Ollama model (defaults to `nomic-embed-text`).         |

## Local embeddings with Ollama

By default, the Worlds Platform™ uses **Ollama** for local embeddings. This ensures your data never leaves your machine.

> [!TIP]
> You can also use **Google Gemini** for embeddings in local development by adding a `GOOGLE_API_KEY` to your environment. See [Configuration Reference](/hosting/configuration) for details.

<Steps>
<Step title="Install Ollama">

Download and install Ollama from [ollama.com](https://ollama.com).

</Step>
<Step title="Pull Embedding Model">

The platform defaults to `nomic-embed-text`. Pull it to your local machine:

```bash
ollama pull nomic-embed-text
```

</Step>
<Step title="Configuration">

The World API server will automatically attempt to connect to the local Ollama instance at `http://127.0.0.1:11434`. You can override this in your environment:

```dotenv
OLLAMA_BASE_URL="http://your-ollama-host:11434"
OLLAMA_EMBEDDINGS_MODEL="nomic-embed-text"
```

</Step>
</Steps>

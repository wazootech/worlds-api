---
title: "Local Setup"
description: "How to run the Worlds Platform™ ecosystem locally."
---

The Worlds Platform™ is designed with a **local-first** philosophy. You can boot the entire ecosystem—including the Management Console and any number of Worlds API instances—using only your local filesystem and Deno runtime.

## Prerequisites

To develop on the Worlds Platform™, you'll need the following tools:

- **Deno** (latest) for the Server, SDK, and CLI.
- **Node.js** (v20+) for the Console and Documentation.
- **Git** for version control.

## Setup the console

The Console orchestrates all other resources. In local mode, it uses `data/workos.json` as a mock identity provider.

<Steps>
<Step title="Clone & Install">

```bash
git clone https://github.com/wazootech/worlds.git
cd worlds/packages/console
npm install
```

</Step>
<Step title="Environment Configuration">

Copy the example environment file. **Skip the WorkOS variables**, to trigger Local Dev Mode.

```bash
cp .env.example .env
```

</Step>
<Step title="Run the Console">

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

</Step>
</Steps>

## Booting world instances

Once the Console is running, it will automatically manage local Worlds API processes.

- **Automatic Boot**: On startup, the Console checks `data/workos.json` and spawns a `deno serve` process for every local organization found.
- **Dynamic Provisioning**: When you create a new Organization in the Console UI, it will:
  1. Generate a local API Key.
  2. Create a local SQLite database in `data/{org_id}/worlds.db`.
  3. Spawn a new Worlds API Server on an available local port.

## Customizing the local user

In Local Dev Mode, you can customize the identity of the mock user session by setting environment variables in `packages/console/.env`:

```dotenv
LOCAL_USER_ID="admin"
LOCAL_USER_EMAIL="admin@wazoo.dev"
LOCAL_USER_FIRST_NAME="System"
LOCAL_USER_LAST_NAME="Admin"
```

These values are used to initialize the `data/workos.json` file if it doesn't already exist.

## Configuration Reference

Here's a list of environment variables you can set for local development:

| Variable                       | Description                                                                |
| :----------------------------- | :------------------------------------------------------------------------- |
| `LIBSQL_URL`                   | (Optional) SQLite URL (defaults to `file:./worlds.db`).                    |
| `LOCAL_USER_EMAIL`             | (Optional) Email for the mock local user.                                  |
| `LOCAL_USER_FIRST_NAME`        | (Optional) First name for the mock local user.                             |
| `LOCAL_USER_ID`                | (Optional) User ID for the mock local user.                                |
| `LOCAL_USER_LAST_NAME`         | (Optional) Last name for the mock local user.                              |
| `OLLAMA_BASE_URL`              | (Optional) Ollama API URL (defaults to `http://localhost:11434`).          |
| `OLLAMA_EMBEDDINGS_MODEL`      | (Optional) Ollama model (defaults to `nomic-embed-text`).                  |
| `OPENROUTER_API_KEY`           | (Optional) For cloud-based embeddings via OpenRouter.                      |
| `OPENROUTER_EMBEDDINGS_MODEL`  | (Optional) OpenRouter model (defaults to `openai/text-embedding-3-small`). |
| `WORLDS_BASE_DIR`              | (Optional) Base directory for world data (defaults to `./worlds`).         |
| `WORLDS_EMBEDDINGS_DIMENSIONS` | (Optional) Unified vector dimensions for DB and AI (defaults to `768`).    |

## Local embeddings with Ollama

By default, the Worlds Platform™ uses **Ollama** for local embeddings. This ensures your data never leaves your machine.

> [!TIP]
> You can also use **OpenRouter** for embeddings in local development by adding an `OPENROUTER_API_KEY` to your environment. See [Configuration Reference](/server/configuration) for details.

<Steps>
<Step title="Install Ollama">

Download and install Ollama from [ollama.com](https://ollama.com).

</Step>
<Step title="Pull Embedding Model">

The platform defaults to `nomic-embed-text`. Pull it to your local machine:

```bash
ollama pull nomic-embed-text
```

</Step>
<Step title="Configuration">

The Worlds API Server will automatically attempt to connect to the local Ollama instance at `http://127.0.0.1:11434`. You can override this in your environment:

```dotenv
OLLAMA_BASE_URL="http://your-ollama-host:11434"
OLLAMA_EMBEDDINGS_MODEL="nomic-embed-text"
```

</Step>
</Steps>
